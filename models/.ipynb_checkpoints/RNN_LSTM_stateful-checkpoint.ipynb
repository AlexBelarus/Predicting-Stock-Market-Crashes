{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Crashes in Financial Markets - RNN LSTM\n",
    "- Datasets: S&P500 (USA), Nikkei225 (Japan), SSE (Shanghai/China), HSI (Hong Kong), BSESN (India), SMI (Switzerland), BVSP (Brazil)\n",
    "- Model: RNN LSTM\n",
    "- Response variable: Crash within 1 / 3 / 6 months (0: no, 1: yes)\n",
    "- Crash definition: Drawdown in 99.5% quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from sklearn import metrics\n",
    "from datetime import datetime, timedelta\n",
    "from pylab import rcParams\n",
    "import os\n",
    "import importlib\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- data preparation -------------------- #\n",
    "os.chdir('/home/roman/Documents/Projects/Bubbles/models')\n",
    "from prepare_data_5 import DataLoader\n",
    "os.chdir('/home/roman/Documents/Projects/Bubbles/data')\n",
    "\n",
    "datasets_original = ['^GSPC.csv', '^N225.csv', 'SSE.csv','^HSI.csv', '^BSESN.csv',\\\n",
    "                     '^SSMI.csv', '^BVSP.csv']\n",
    "dataset_names = ['S&P 500', 'N225', 'SSE', 'HSI', 'BSESN', 'SMI', 'BVSP']\n",
    "data = DataLoader(datasets_original, dataset_names)\n",
    "\n",
    "# specify drawdown thresholds for crashes (determined in exploration.ipynb):\n",
    "crash_thresholds = [-0.091, -0.109, -0.120, -0.144, -0.166, -0.110, -0.233] # <-- Jacobsson\n",
    "#crash_thresholds = [-0.1053, -0.1495, -0.1706, -0.2334, -0.1563, -0.1492, -0.2264] # <-- Sornette\n",
    "df_combined, drawdowns, crashes = data.get_df_combined(crash_thresholds)\n",
    "\n",
    "months = 3               # <-- predict if crash n months ahead\n",
    "select_features = False  # <-- if True: 8 time windows for mean price change and vol year\n",
    "sequence = 5             # <-- number of days lookback as input(only if select_features=False)\n",
    "additional_feat = False  # <-- if True: add mean price change and volatility for 4 time widnows over 252 days\n",
    "batch_size = 64          # <-- batch size needs to be specified to satisfy stateful=True\n",
    "#vol = False             # <-- if True: include 10 day volatility for each day in sequence (only in prepare_data_2)\n",
    "dfs_xy = data.get_df_xy(months=months, sequence=sequence, df_combined=df_combined, crashes=crashes, \\\n",
    "                        batch_size=batch_size, select_features=select_features, additional_feat=additional_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- RNN LSTM model -------------------- #\n",
    "model_name = 'RNN LSTM'\n",
    "neurons = 50\n",
    "dropout = 0\n",
    "optimizer = 'adam'\n",
    "loss = 'mse'   # 'binary_crossentropy'\n",
    "activation = 'linear'\n",
    "stateful = True\n",
    "inp_tsteps = sequence + 8 * additional_feat\n",
    "def rnn_lstm(inp_tsteps, inp_dim, neurons, dropout):\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(neurons, input_shape=(inp_tsteps, inp_dim), return_sequences=True))\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, inp_tsteps, inp_dim), \\\n",
    "                   stateful=stateful, return_sequences=True))\n",
    "    #model.add(Dropout(dropout))\n",
    "    #model.add(LSTM(neurons, return_sequences=True))\n",
    "    model.add(LSTM(neurons, stateful=stateful, return_sequences=False))\n",
    "    #model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=activation))   # 'sigmoid'\n",
    "    return model\n",
    "model = rnn_lstm(neurons=neurons, inp_tsteps=inp_tsteps, inp_dim=1, dropout=dropout)\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -------------------- Train and test RNN LSTM model -------------------- #\n",
    "epochs = 100\n",
    "y_train_all = []\n",
    "y_test_all = []\n",
    "y_pred_tr_all = []\n",
    "y_pred_t_all = []\n",
    "os.chdir('/home/roman/Documents/Projects/Bubbles/models/model_weights/')\n",
    "for test_data in dataset_names:\n",
    "    model = rnn_lstm(neurons=neurons, inp_tsteps=inp_tsteps, inp_dim=1, dropout=dropout)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy']) \n",
    "    print('------------------------------------------------------')\n",
    "    print('Testdata: ' + str(test_data))\n",
    "    print('------------------------------------------------------')\n",
    "    for e in range(epochs):\n",
    "        np_train_l = data.get_train_stateful(dfs_xy, dataset_names, test_data=test_data)\n",
    "        for i, np_tr in enumerate(np_train_l):\n",
    "            print('epoch: ' + str(e + 1) + ' dataset: ' + str(i + 1))\n",
    "            x_tr = np_tr[:, 0:-1]             \n",
    "            x_tr = np.expand_dims(x_tr, axis=2)\n",
    "            y_tr = np_tr[:, -1].astype(int)   \n",
    "            model.fit(x_tr, y_tr, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "            model.reset_states()\n",
    "            if (e + 1) % 5 == 0 and i == len(np_train_l) - 1:\n",
    "                model.save_weights('stateful_{0}_{1}.hdf5'.format(test_data, e + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Load weights and predict results -------------------- #\n",
    "epochs = 2 # <-- change to load model weights from previous epochs\n",
    "y_train_all = []\n",
    "y_test_all = []\n",
    "y_pred_tr_all = []\n",
    "y_pred_t_all = []\n",
    "for test_data in dataset_names:\n",
    "    np_train, np_test = data.get_train_test(dfs_xy, dataset_names, test_data=test_data)\n",
    "    x_train = np_train[:, 0:-1]             \n",
    "    x_train = np.expand_dims(x_train, axis=2)\n",
    "    y_train = np_train[:, -1].astype(int)   \n",
    "    y_train_all.append(y_train)\n",
    "    x_test = np_test[:, 0:-1]               \n",
    "    x_test = np.expand_dims(x_test, axis=2)\n",
    "    y_test = np_test[:, -1].astype(int) \n",
    "    y_test_all.append(y_test)\n",
    "    model.load_weights('stateful_{0}_{1}.hdf5'.format(test_data, epochs))\n",
    "    y_pred_tr = model.predict(x_train, batch_size=batch_size) \n",
    "    y_pred_tr_all.append(y_pred_tr)\n",
    "    y_pred_t = model.predict(x_test, batch_size=batch_size)\n",
    "    y_pred_t_all.append(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Find best threshold -------------------- #\n",
    "#pct_pos = 0.10   # <-- tune: increase leads to higher recall, less precision\n",
    "beta = 2\n",
    "precision_tr_all, recall_tr_all, accuracy_tr_all = [], [], []\n",
    "precision_t_all, recall_t_all, accuracy_t_all = [], [], [] \n",
    "fbeta_tr_all, fbeta_t_all = [], []\n",
    "thresholds = [0.02, 0.0225, 0.025, 0.0275, 0.03, 0.0325, 0.035, 0.0375, 0.040, 0.0425, 0.045]\n",
    "for threshold in thresholds:\n",
    "    precision_tr, recall_tr, accuracy_tr = [], [], []\n",
    "    precision_t, recall_t, accuracy_t = [], [], []\n",
    "    y_pred_t_bin_all, y_pred_tr_bin_all = [], []\n",
    "    score_fbeta_tr, score_fbeta_t = [], []\n",
    "    for y_train, y_test, y_pred_tr, y_pred_t in zip(y_train_all, y_test_all, \\\n",
    "                                                    y_pred_tr_all, y_pred_t_all):\n",
    "        #y_pred_tr_bin = y_pred_tr > np.percentile(y_pred_tr, 100 * (1-pct_pos))\n",
    "        y_pred_tr_bin = y_pred_tr > threshold\n",
    "        y_pred_tr_bin = y_pred_tr_bin.astype(int)\n",
    "        y_pred_tr_bin_all.append(y_pred_tr_bin)\n",
    "        precision_tr.append(metrics.precision_score(y_train, y_pred_tr_bin))\n",
    "        recall_tr.append(metrics.recall_score(y_train, y_pred_tr_bin))\n",
    "        accuracy_tr.append(metrics.accuracy_score(y_train, y_pred_tr_bin))\n",
    "        score_fbeta_tr.append(metrics.fbeta_score(y_train, y_pred_tr_bin, beta=beta))\n",
    "        #y_pred_t_bin = y_pred_t > np.percentile(y_pred_t, 100 * (1-pct_pos))\n",
    "        y_pred_t_bin = y_pred_t > threshold\n",
    "        y_pred_t_bin = y_pred_t_bin.astype(int)\n",
    "        y_pred_t_bin_all.append(y_pred_t_bin)\n",
    "        precision_t.append(metrics.precision_score(y_test, y_pred_t_bin))\n",
    "        recall_t.append(metrics.recall_score(y_test, y_pred_t_bin))\n",
    "        accuracy_t.append(metrics.accuracy_score(y_test, y_pred_t_bin))\n",
    "        score_fbeta_t.append(metrics.fbeta_score(y_test, y_pred_t_bin, beta=beta))\n",
    "    precision_tr_all.append(np.mean(precision_tr)) \n",
    "    precision_t_all.append(np.mean(precision_t)) \n",
    "    recall_tr_all.append(np.mean(recall_tr)) \n",
    "    recall_t_all.append(np.mean(recall_t))\n",
    "    accuracy_tr_all.append(np.mean(accuracy_tr)) \n",
    "    accuracy_t_all.append(np.mean(accuracy_t))\n",
    "    fbeta_tr_all.append(np.mean(score_fbeta_tr))\n",
    "    fbeta_t_all.append(np.mean(score_fbeta_t))\n",
    "rcParams['figure.figsize'] = 14, 4\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(thresholds, precision_tr_all, color='blue')\n",
    "plt.plot(thresholds, precision_t_all, color='red')\n",
    "plt.title('Precision by threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(['training set', 'test set'])\n",
    "plt.grid()\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(thresholds, recall_tr_all, color='blue')\n",
    "plt.plot(thresholds, recall_t_all, color='red')\n",
    "plt.title('Recall by threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(['training set', 'test set'])\n",
    "plt.grid()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(thresholds, fbeta_tr_all, color='blue')\n",
    "plt.plot(thresholds, fbeta_t_all, color='red')\n",
    "plt.title('F-beta score by threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F-beta score')\n",
    "plt.legend(['training set', 'test set'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Evaluate results -------------------- #\n",
    "#pct_pos = 0.10   # <-- tune: increase leads to higher recall, less precision\n",
    "threshold = 0.035\n",
    "precision_tr, recall_tr, accuracy_tr = [], [], []\n",
    "precision_t, recall_t, accuracy_t = [], [], []\n",
    "y_pred_t_bin_all, y_pred_tr_bin_all = [], []\n",
    "score_fbeta_tr, score_fbeta_t = [], []\n",
    "for y_train, y_test, y_pred_tr, y_pred_t in zip(y_train_all, y_test_all, \\\n",
    "                                                y_pred_tr_all, y_pred_t_all):\n",
    "    #y_pred_tr_bin = y_pred_tr > np.percentile(y_pred_tr, 100 * (1-pct_pos))\n",
    "    y_pred_tr_bin = y_pred_tr > threshold\n",
    "    y_pred_tr_bin = y_pred_tr_bin.astype(int)\n",
    "    y_pred_tr_bin_all.append(y_pred_tr_bin)\n",
    "    precision_tr.append(metrics.precision_score(y_train, y_pred_tr_bin))\n",
    "    recall_tr.append(metrics.recall_score(y_train, y_pred_tr_bin))\n",
    "    accuracy_tr.append(metrics.accuracy_score(y_train, y_pred_tr_bin))\n",
    "    score_fbeta_tr.append(metrics.fbeta_score(y_train, y_pred_tr_bin, beta=beta))\n",
    "    #y_pred_t_bin = y_pred_t > np.percentile(y_pred_t, 100 * (1-pct_pos))\n",
    "    y_pred_t_bin = y_pred_t > threshold\n",
    "    y_pred_t_bin = y_pred_t_bin.astype(int)\n",
    "    y_pred_t_bin_all.append(y_pred_t_bin)\n",
    "    precision_t.append(metrics.precision_score(y_test, y_pred_t_bin))\n",
    "    recall_t.append(metrics.recall_score(y_test, y_pred_t_bin))\n",
    "    accuracy_t.append(metrics.accuracy_score(y_test, y_pred_t_bin))\n",
    "    score_fbeta_t.append(metrics.fbeta_score(y_test, y_pred_t_bin, beta=beta))\n",
    "\n",
    "y_tr_pred_pos = [np.mean(y_pred) for y_pred in y_pred_tr_bin_all]\n",
    "y_t_pred_pos = [np.mean(y_pred) for y_pred in y_pred_t_bin_all]\n",
    "d = {'precision_tr': np.round(precision_tr,2), \\\n",
    "     'recall_tr': np.round(recall_tr,2), 'accuracy_tr': np.round(accuracy_tr,2), \\\n",
    "     'score_fbeta_tr': np.round(score_fbeta_tr,2), \\\n",
    "     'precision_t': np.round(precision_t,2), \\\n",
    "     'recall_t': np.round(recall_t,2), 'accuracy_t': np.round(accuracy_t,2), \\\n",
    "     'score_fbeta_t': np.round(score_fbeta_t,2)}\n",
    "results = pd.DataFrame.from_dict(d, orient='index')\n",
    "results.columns = dataset_names\n",
    "print('Results - ' + model_name + ':')\n",
    "print('\\n')\n",
    "print('Predict crash in:         ' + str(months) + ' months')\n",
    "print('Number of epochs:         ' + str(epochs))\n",
    "print('Sequence length:          ' + str(sequence))\n",
    "print('Number of neurons/layer: ' + str(neurons))\n",
    "print('Batch size:               ' + str(batch_size))\n",
    "print('Optimizer:                ' + str(optimizer))\n",
    "print('Loss function:            ' + str(loss))\n",
    "print('\\n')\n",
    "print('Results for each train/test split:')\n",
    "print(results)\n",
    "print('\\n')\n",
    "\n",
    "# calculate precision, recall, accuracy for comparable random model\n",
    "sum_tr = 0\n",
    "sum_t = 0\n",
    "pos_tr = 0\n",
    "pos_t = 0\n",
    "sum_tr_pred = 0\n",
    "sum_t_pred = 0\n",
    "pos_tr_pred = 0\n",
    "pos_t_pred = 0\n",
    "for y_tr, y_t, y_tr_pr, y_t_pr in zip(y_train_all, y_test_all, y_pred_tr_bin_all, \\\n",
    "                y_pred_t_bin_all):\n",
    "    sum_tr += len(y_tr)\n",
    "    pos_tr += sum(y_tr)\n",
    "    sum_t += len(y_t)\n",
    "    pos_t += sum(y_t)\n",
    "    sum_tr_pred += len(y_tr_pr)\n",
    "    sum_t_pred += len(y_t_pr)\n",
    "    pos_tr_pred += sum(y_tr_pr)[0]\n",
    "    pos_t_pred += sum(y_t_pr)[0]\n",
    "y_train_pos_actual = pos_tr / sum_tr\n",
    "y_train_pos_pred = pos_tr_pred / sum_tr_pred\n",
    "rnd_TP = y_train_pos_pred * y_train_pos_actual\n",
    "rnd_FP = y_train_pos_pred * (1 - y_train_pos_actual)\n",
    "rnd_TN = (1 - y_train_pos_pred) * (1 - y_train_pos_actual)\n",
    "rnd_FN = (1 - y_train_pos_pred) * y_train_pos_actual\n",
    "rnd_pr_tr = rnd_TP / (rnd_TP + rnd_FP)\n",
    "rnd_re_tr = rnd_TP / (rnd_TP + rnd_FN)\n",
    "rnd_ac_tr = rnd_TP + rnd_TN\n",
    "y_test_pos_actual = pos_t / sum_t\n",
    "y_test_pos_pred = pos_t_pred / sum_t_pred\n",
    "rnd_TP = y_test_pos_pred * y_test_pos_actual\n",
    "rnd_FP = y_test_pos_pred * (1 - y_test_pos_actual)\n",
    "rnd_TN = (1 - y_test_pos_pred) * (1 - y_test_pos_actual)\n",
    "rnd_FN = (1 - y_test_pos_pred) * y_test_pos_actual\n",
    "rnd_pr_t = rnd_TP / (rnd_TP + rnd_FP)\n",
    "rnd_re_t = rnd_TP / (rnd_TP + rnd_FN)\n",
    "rnd_ac_t = rnd_TP + rnd_TN\n",
    "\n",
    "print('Results average over all train/test splits:')\n",
    "print('Number of features: ' + str(sequence) + '; number of rows: ' \\\n",
    "      + str(sum_tr + sum_t))\n",
    "print('Positive train cases actual:        '+ str(round(y_train_pos_actual, 2)))\n",
    "print('Positive train cases predicted:     '+ str(round(y_train_pos_pred, 2)))\n",
    "print('Avg precision train (model/random): '+ str(round(np.mean(precision_tr), 2)) +' / '+str(round(rnd_pr_tr, 2)))\n",
    "print('Avg recall train (model/random):    '+ str(round(np.mean(recall_tr), 2))+' / '+str(round(rnd_re_tr, 2)))\n",
    "print('Avg accuracy train (model/random):  '+ str(round(np.mean(accuracy_tr), 2))+' / '+str(round(rnd_ac_tr, 2)))\n",
    "print('Score train fbeta:                  '+ str(round(np.mean(score_fbeta_tr), 2)))\n",
    "print('Positive test cases actual:         '+ str(round(y_test_pos_actual, 2)))\n",
    "print('Positive test cases predicted:      '+ str(round(y_test_pos_pred, 2)))\n",
    "print('Avg precision test (model/random):  '+ str(round(np.mean(precision_t), 2))+' / '+str(round(rnd_pr_t, 2)))\n",
    "print('Avg recall test (model/random):     '+ str(round(np.mean(recall_t), 2))+' / '+str(round(rnd_re_t, 2)))\n",
    "print('Avg accuracy test (model/random):   '+ str(round(np.mean(accuracy_t), 2))+' / '+str(round(rnd_ac_t, 2)))\n",
    "print('Score test fbeta:                   '+ str(round(np.mean(score_fbeta_t), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -------------------- Plot results -------------------- #\n",
    "test_data = 'S&P 500'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [datetime.strptime('1984-01-01', '%Y-%m-%d'), datetime.strptime('1994-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2007-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('1991-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2002-01-01', '%Y-%m-%d'), datetime.strptime('2010-01-01', '%Y-%m-%d')]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "\n",
    "test_data = 'N225'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [datetime.strptime('1984-01-01', '%Y-%m-%d'), datetime.strptime('2005-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2013-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('1992-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2012-01-01', '%Y-%m-%d'), datetime.strptime('2017-01-01', '%Y-%m-%d')]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()      \n",
    " \n",
    "    \n",
    "test_data = 'SSE'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [df.index[0], datetime.strptime('2004-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2010-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('2002-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2010-01-01', '%Y-%m-%d'), df.index[-1]]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "    \n",
    "test_data = 'HSI'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [df.index[0], datetime.strptime('1995-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2005-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('1990-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('1999-01-01', '%Y-%m-%d'), datetime.strptime('2010-01-01', '%Y-%m-%d')]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "    \n",
    "test_data = 'BSESN'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [datetime.strptime('1995-01-01', '%Y-%m-%d'), datetime.strptime('2005-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('2003-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2010-01-01', '%Y-%m-%d')]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "\n",
    "test_data = 'SMI'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [datetime.strptime('1994-01-01', '%Y-%m-%d'), datetime.strptime('2000-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2010-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('2000-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2006-01-01', '%Y-%m-%d'), datetime.strptime('2016-01-01', '%Y-%m-%d')]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "\n",
    "test_data = 'BVSP'\n",
    "i = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "dfs_predict = data.split_results(df_combined, dfs_xy, dataset_names, test_data, \\\n",
    "            y_pred_t_bin_all[i], y_pred_tr_bin_all[i], y_train_all[i], y_test_all[i])\n",
    "df = dfs_predict[i]\n",
    "c = crashes[i]\n",
    "t_start = [df.index[0], datetime.strptime('2004-01-01', '%Y-%m-%d')]\n",
    "t_end = [datetime.strptime('2000-01-01', '%Y-%m-%d'), \\\n",
    "           datetime.strptime('2010-01-01', '%Y-%m-%d')]\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "for t1, t2 in zip(t_start, t_end):\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[2.5, 1, 1])\n",
    "    plt.subplot(gs[0])\n",
    "    y_start = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) < 0].index)\n",
    "    y_end = list(df[t1:t2][df.loc[t1:t2, 'y'].diff(-1) > 0].index)\n",
    "    crash_st = list(filter(lambda x: x > t1 and x < t2, c['crash_st']))\n",
    "    crash_end = list(filter(lambda x: x > t1 and x < t2, c['crash_end']))\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    df_norm = df['price'][t1:t2] / df['price'][t1:t2].max()\n",
    "    plt.plot(df_norm[t1:t2], color='blue') \n",
    "    plt.title(model_name + ' Testcase: ' + test_data + ' ' + str(t1.year) + '-' \\\n",
    "              + str(t2.year))\n",
    "    plt.legend(['price', 'downturn / crash'])\n",
    "    plt.xticks([])\n",
    "    plt.grid()     \n",
    "    plt.subplot(gs[1])\n",
    "    plt.plot(df.loc[t1:t2, 'vol'])\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['Volatility'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.xticks([])\n",
    "    plt.subplot(gs[2])\n",
    "    plt.plot(df['y'][t1:t2], color='black')\n",
    "    plt.plot(df['y_pred'][t1:t2].rolling(10).mean(), color='darkred', linewidth=0.8)\n",
    "    [plt.axvspan(x1, x2, alpha=0.2, color='red') for x1, x2 in zip(y_start, y_end)]\n",
    "    [plt.axvspan(x1, x2, alpha=0.5, color='red') for x1, x2 in zip(crash_st, crash_end)]\n",
    "    plt.legend(['crash within 6m', 'crash predictor'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
